{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import bisect\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConformalPredictor():\n",
    "    def __init__(self, n_trees=100, s=2, gamma=1, labda=1, tree_max_depth=None, combination=1, data_name=None, random_state=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.s = s\n",
    "        self.labda = labda\n",
    "        self.gamma = gamma\n",
    "        self.combination = combination\n",
    "        self.data_name = data_name\n",
    "        self.w = np.ones(n_trees) / n_trees\n",
    "        self.model = RandomForestClassifier(n_estimators=n_trees, max_depth=tree_max_depth, random_state=random_state)\n",
    "\n",
    "    def fit(self, X_train, y_train, X_calib, y_calib):\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "        # Store class information\n",
    "        self.classes = self.model.classes_\n",
    "        self.class_to_index = {c: i for i, c in enumerate(self.classes)}\n",
    "\n",
    "        # calibration nonconformity scores\n",
    "        # for each sample:\n",
    "        # nonconformity_score = 1 - p(correct_class|x_calib)\n",
    "        prob_calib = self.model.predict_proba(X_calib)\n",
    "        self.calibration_scores_by_class = {c: [] for c in self.classes}\n",
    "\n",
    "        for i, true_class in enumerate(y_calib):\n",
    "            class_idx = self.class_to_index[true_class]\n",
    "            # nonconformity score for this instance is 1 - probability of the true class\n",
    "            nonconformity_score = 1 - prob_calib[i, class_idx]\n",
    "            self.calibration_scores_by_class[true_class].append(nonconformity_score)\n",
    "\n",
    "        for c in self.classes:\n",
    "            self.calibration_scores_by_class[c] = np.sort(self.calibration_scores_by_class[c])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _nonconformity_score_for_class(self, X, class_idx):\n",
    "        prob = self.model.predict_proba(X)\n",
    "        return 1 - prob[:, class_idx]\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # compute the conformal p-values for each class\n",
    "        # for a given test point, p-value for class c_j is:\n",
    "\n",
    "        n_test = X.shape[0]\n",
    "        p_values = np.zeros((n_test, len(self.classes)))\n",
    "\n",
    "        for j, c in enumerate(self.classes):\n",
    "            test_scores = self._nonconformity_score_for_class(X, j)\n",
    "            sorted_scores = self.calibration_scores_by_class[c]\n",
    "            N_j = len(sorted_scores)\n",
    "\n",
    "            # for each test sample, count num calibration scores are >= test_score\n",
    "            # p-value = (count + 1)/(N_j + 1)\n",
    "            for i, score in enumerate(test_scores):\n",
    "                idx = bisect.bisect_left(sorted_scores, score)\n",
    "                count = N_j - idx\n",
    "                p_values[i, j] = (count + 1) / (N_j + 1) if N_j > 0 else 1.0\n",
    "\n",
    "        return p_values\n",
    "\n",
    "    def predict(self, X, alpha=0.05):\n",
    "        # get conformal set of classes whose p-value > alpha\n",
    "        p_values = self.predict_proba(X)\n",
    "        # thresh at alpha to get sets of classes\n",
    "        conformal_sets = (p_values > alpha).astype(int)\n",
    "        mlb = MultiLabelBinarizer(classes=self.classes)\n",
    "        mlb.fit([self.classes])\n",
    "        pred = mlb.inverse_transform(conformal_sets)\n",
    "\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u65_score(y_test, y_pred):\n",
    "        imprecise_predictions = y_pred\n",
    "        indeterminate_instance = (imprecise_predictions == -1)\n",
    "        determinate_instance = (imprecise_predictions != -1)\n",
    "        \n",
    "        # calculate single-set length\n",
    "        single_set_length = len(y_test) - sum(indeterminate_instance)\n",
    "        \n",
    "        # calculate determinacy\n",
    "        determinacy = single_set_length/len(y_test)\n",
    "        determinacy = round(determinacy*100, 2)\n",
    "        \n",
    "        # calculate single-set accuracy\n",
    "        single_set_accuracy = sum(y_test[determinate_instance]==imprecise_predictions[determinate_instance])/single_set_length\n",
    "        single_set_accuracy = round(single_set_accuracy*100, 2)\n",
    "        \n",
    "        # claculate u65\n",
    "        u65_score = round(65 + (single_set_accuracy - 65)*determinacy/100, 2)\n",
    "        return u65_score, single_set_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example use case with german credit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "640\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\"\n",
    "columns = [\n",
    "    \"Status_of_existing_checking_account\", \"Duration_in_month\", \"Credit_history\",\n",
    "    \"Purpose\", \"Credit_amount\", \"Savings_account_bonds\", \"Employment_since\",\n",
    "    \"Installment_rate\", \"Personal_status_and_sex\", \"Other_debtors\", \"Present_residence_since\",\n",
    "    \"Property\", \"Age_in_years\", \"Other_installment_plans\", \"Housing\", \"Number_of_existing_credits\",\n",
    "    \"Job\", \"Number_of_people_liable\", \"Telephone\", \"Foreign_worker\", \"Target\"\n",
    "]\n",
    "\n",
    "data = pd.read_csv(url, delimiter=' ', names=columns, header=None)\n",
    "X = data.drop(columns=[\"Target\"])\n",
    "y = data[\"Target\"]\n",
    "y = y - 1\n",
    "categorical_features = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "X_encoded = encoder.fit_transform(X[categorical_features])\n",
    "X_encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(categorical_features))\n",
    "\n",
    "X = X.drop(columns=categorical_features)\n",
    "X = pd.concat([X.reset_index(drop=True), X_encoded_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "X_train_calib, X_test, y_train_calib, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_train, X_calib, y_train, y_calib = train_test_split(X_train_calib, y_train_calib, test_size=0.2, random_state=42, stratify=y_train_calib)\n",
    "print(len(X_calib))\n",
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpc = ConformalPredictor()\n",
    "cpc.fit(X_train, y_train, X_calib, y_calib)\n",
    "cpc_preds = cpc.predict(X_test, alpha=0.1)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_prd = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30     0\n",
      "128    0\n",
      "289    1\n",
      "216    0\n",
      "966    1\n",
      "      ..\n",
      "522    1\n",
      "977    0\n",
      "52     0\n",
      "542    1\n",
      "423    0\n",
      "Name: Target, Length: 200, dtype: int64\n",
      "[-1, -1, 1, -1, -1, -1, -1, -1, 1, 0, 0, -1, 0, -1, -1, 0, -1, 0, 0, 0, -1, 0, -1, 1, -1, -1, 0, -1, 0, 0, -1, -1, -1, 1, -1, 1, 1, 1, 0, 1, -1, -1, -1, -1, -1, 0, -1, 1, -1, 0, 0, 0, -1, 1, 1, -1, 0, -1, 1, 1, -1, 1, -1, 1, 0, -1, 0, 0, 1, 1, -1, -1, 0, -1, -1, 0, -1, 0, 1, 0, 1, -1, -1, 0, 0, -1, -1, 0, 1, -1, 1, 1, -1, -1, -1, 0, 1, -1, -1, 1, 0, 0, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, 1, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, -1, 1, -1, -1, -1, 1, 1, 1, 1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, 0, 0, 0, 0, -1, 0, -1, -1, 1, -1, -1, -1, -1, 0, -1, 0, -1, 0, 1, -1, -1, -1, -1, 0, -1, 0, 0, 1, 0, 0, 1, 1, -1, -1, -1, 1, 1, -1, 1, 0, 0, 0, -1, 1, 0, -1, 0, 1, 0, 0, -1, 0]\n",
      "Single set acc for Random Forest: 76.0, u65: 76.0\n",
      "Single set acc for conformal pred: 80.0, u65: 72.5\n"
     ]
    }
   ],
   "source": [
    "cpc_pred_transformed = [\n",
    "    -1 if p == (0, 1) else p[0] \n",
    "    for p in cpc_preds\n",
    "]\n",
    "print(y_test)\n",
    "print(cpc_pred_transformed)\n",
    "u65, single_set_acc = u65_score(y_test, rfc_prd)\n",
    "print(f\"Single set acc for Random Forest: {single_set_acc}, u65: {u65}\")\n",
    "u65, single_set_acc = u65_score(y_test, np.array(cpc_pred_transformed))\n",
    "print(f\"Single set acc for conformal pred: {single_set_acc}, u65: {u65}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example use case on compas data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7185\n",
      "7185\n",
      "1150\n",
      "4598\n",
      "1437\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/compas/compas_data_combined_matches.csv')\n",
    "columns_to_drop = ['FirstName', 'LastName', 'DateOfBirth', 'id', 'v_decile_score', 'DecileScore_Risk of Failure to Appear','race', 'DecileScore_Risk of Recidivism', 'DecileScore_Risk of Violence', 'RawScore_Risk of Failure to Appear', 'RawScore_Risk of Recidivism', 'RawScore_Risk of Violence', '_merge', 'sex', 'c_charge_desc']\n",
    "rf_dataset = df.drop(columns=columns_to_drop)\n",
    "## Remove Nans\n",
    "na_counts = rf_dataset.isna().sum()\n",
    "na_columns = na_counts[na_counts > 0] \n",
    "nans = na_columns.to_dict()\n",
    "columns_to_remove = []\n",
    "for key in nans.keys():\n",
    "    columns_to_remove.append(key)\n",
    "rf_dataset = rf_dataset.drop(columns=columns_to_remove)\n",
    "labels = rf_dataset.two_year_recid\n",
    "rf_dataset = rf_dataset.drop(columns=['two_year_recid', 'is_recid', 'score_text'])\n",
    "print(len(rf_dataset))\n",
    "print(len(labels))\n",
    "X_train_calib, X_test, y_train_calib, y_test = train_test_split(rf_dataset, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_calib, y_train, y_calib = train_test_split(X_train_calib, y_train_calib, test_size=0.2, random_state=42)\n",
    "print(len(X_calib))\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpc = ConformalPredictor()\n",
    "cpc.fit(X_train, y_train, X_calib, y_calib)\n",
    "cpc_preds = cpc.predict(X_test, alpha=0.1)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_prd = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1315    1.0\n",
      "1893    1.0\n",
      "6937    0.0\n",
      "7021    0.0\n",
      "4908    1.0\n",
      "       ... \n",
      "4874    1.0\n",
      "4664    0.0\n",
      "940     0.0\n",
      "3817    0.0\n",
      "5251    0.0\n",
      "Name: two_year_recid, Length: 1437, dtype: float64\n",
      "Single set acc for Random Forest: 62.28, u65: 62.28\n",
      "Single set acc for conformal pred: 70.78, u65: 66.95\n"
     ]
    }
   ],
   "source": [
    "cpc_pred_transformed = [\n",
    "    -1 if p == (0, 1) else p[0] \n",
    "    for p in cpc_preds\n",
    "]\n",
    "u65, single_set_acc = u65_score(y_test, rfc_prd)\n",
    "print(f\"Single set acc for Random Forest: {single_set_acc}, u65: {u65}\")\n",
    "u65, single_set_acc = u65_score(y_test, np.array(cpc_pred_transformed))\n",
    "print(f\"Single set acc for conformal pred: {single_set_acc}, u65: {u65}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataviz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
